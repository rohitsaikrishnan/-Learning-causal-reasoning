{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Causal Models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyekZ0mfjcRSPXYM7HoZUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitsaikrishnan/-Learning-causal-reasoning/blob/main/Neural_Causal_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q-ZAhTmlCoo",
        "outputId": "1dbf7f14-9cf3-45a9-83e2-4b9602c09b07"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmX9ELxSlOBr",
        "outputId": "e09a3be8-14da-483a-c7e7-0dd16554f708"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Oct 30 19:35:30 2019\n",
        "@author: NaNwani\n",
        "\"\"\"\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, LeakyReLU, Dropout\n",
        "from keras.initializers import RandomNormal as normal\n",
        "from keras.utils import to_categorical\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# data set parameters\n",
        "M=20    # number of variables in the data set\n",
        "N=10     # number of values each variable can take\n",
        "T=100000 # number of samples\n",
        "\n",
        "# Multi layer perceptron parameters\n",
        "num_hidden_nodes = 200\n",
        "train_epochs = 100\n",
        "val_split = 0.3\n",
        "\n",
        "initializer_kernel = normal(mean=0, stddev=2)\n",
        "initializer_bias = normal(mean=0, stddev=2)\n",
        "\n",
        "\n",
        "def get_MLP(isTraineeMLP, *numNodesList):\n",
        "    MLP = Sequential()\n",
        "\n",
        "    numLayers = len(numNodesList) - 1\n",
        "    if numLayers == 0:\n",
        "        print('MLP should have at least one layer')\n",
        "        return MLP\n",
        "\n",
        "    if isTraineeMLP:\n",
        "        MLP.add(Dropout(0.8))\n",
        "\n",
        "    # hidden layers\n",
        "    for l in range(numLayers-1):\n",
        "        if isTraineeMLP:\n",
        "            MLP.add(Dense(numNodesList[l+1],input_dim=numNodesList[l]))\n",
        "            #MLP.add(Dropout(0.1))\n",
        "        else:\n",
        "            MLP.add(Dense(numNodesList[l+1],\n",
        "                          input_dim=numNodesList[l],\n",
        "                          kernel_initializer=initializer_kernel,\n",
        "                          bias_initializer=initializer_bias))\n",
        "            MLP.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "    # output layer\n",
        "    if isTraineeMLP:\n",
        "        MLP.add(Dense(numNodesList[-1],\n",
        "                  activation='sigmoid',\n",
        "                  kernel_initializer=initializer_kernel,\n",
        "                  bias_initializer=initializer_bias))\n",
        "    else:\n",
        "        MLP.add(Dense(numNodesList[-1],activation='sigmoid'))\n",
        "\n",
        "    return MLP\n",
        "\n",
        "\n",
        "def get_one_hot_mask(mask, N):\n",
        "    one_hot_mask = np.ones((N,1))*(N*mask)+(np.repeat(range(N),len(mask)).reshape(N,len(mask)))\n",
        "    one_hot_mask = (one_hot_mask.reshape(N*len(mask))).astype(int)\n",
        "    return one_hot_mask\n",
        "    \n",
        "\n",
        "\n",
        "# function to generate one hot encoded data set: inputs in order: \n",
        "# M-number of variables, N-number of states each variable takes, T-number of samples in dataset; C-adjacency matrix of DAG\n",
        "def generate_dataset_one_hot(M,N,T,C,GTmodels):\n",
        "    # initialize the independent variable uniformly randomly\n",
        "    X = np.random.randint(N, size=T)\n",
        "    \n",
        "    inputData = np.zeros((T,M))     # raw data from ground truth models\n",
        "    inputDataOneHot = np.zeros((T,M*N))\n",
        "    \n",
        "    inputData[range(T),0] = X\n",
        "    inputDataOneHot[np.ix_(range(T),range(N))] = to_categorical(X,N)   #one hot encoding\n",
        "    \n",
        "    # define the groud truth models and generate the dataset\n",
        "    for m_index in range(M-1):  #skip first variable which is independent of the rest\n",
        "        print('ground truth model', m_index+1)\n",
        "        GTmodels.append(get_MLP(0,M*N,num_hidden_nodes,N))\n",
        "        \n",
        "        inp_ind = np.nonzero(C[m_index+1,:])\n",
        "        mask_ind = np.where(C[m_index+1,:]==0)\n",
        "        if (len(inp_ind[0]) == 0):\n",
        "            C[m_index+1,0] = 1\n",
        "            mask_ind = np.zero(C[m_index+1,:])\n",
        "        mask_cols = get_one_hot_mask(mask_ind[0], N)\n",
        "    \n",
        "        inp = inputDataOneHot.copy()\n",
        "        inp[np.ix_(range(T),mask_cols)] = 0\n",
        "    \n",
        "        pred = GTmodels[m_index].predict(inp)\n",
        "        #print(pred)\n",
        "        output = np.argmax(pred,axis=1)\n",
        "        #print(output)\n",
        "        inputDataOneHot[range(T),(m_index+1)*N+output] = 1\n",
        "        inputData[range(T),(m_index+1)] = output\n",
        "        \n",
        "    #print(inputData)\n",
        "    print(sum(inputData))\n",
        "    \n",
        "    return inputDataOneHot\n",
        "\n",
        "# function to define and tain the MLPs\n",
        "def train_MLPs(M,N,T,C,traineeModels,inpOneHot):\n",
        "    T1 = 10\n",
        "    T0 = T - T1\n",
        "    batch = int(T0 / 100)\n",
        "\n",
        "    es = EarlyStopping(monitor='loss', min_delta=1e-6, patience=3)\n",
        "    \n",
        "    for m_index in range(M):    #create a MLP for each variable\n",
        "        print('trainee model', m_index)\n",
        "        \n",
        "        traineeModels.append(get_MLP(1,M*N,num_hidden_nodes,N))\n",
        "        traineeModels[m_index].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "    \n",
        "        inp = inpOneHot[:T0,:].copy()\n",
        "        \n",
        "        op_mask_cols = get_one_hot_mask(np.array([m_index]), N)\n",
        "        inp[np.ix_(range(T0),op_mask_cols)] = np.zeros((T0,len(op_mask_cols)))\n",
        "    \n",
        "        output = inpOneHot[np.ix_(range(T0),op_mask_cols)].copy()\n",
        "        traineeModels[m_index].fit(inp, output, epochs=train_epochs, batch_size=batch, validation_split=val_split, callbacks=[es])\n",
        "    \n",
        "        test_inp = inpOneHot[T0:T0+T1,:].copy()\n",
        "        true_out = (test_inp[np.ix_(range(T1),op_mask_cols)]).copy()\n",
        "        test_inp[np.ix_(range(T1),op_mask_cols)] = np.zeros((T1,len(op_mask_cols)))\n",
        "        \n",
        "        pred = traineeModels[m_index].predict(test_inp)\n",
        "        pred = np.argmax(pred,axis=1)\n",
        "    \n",
        "        print('test out', pred)\n",
        "        print('true out', np.argmax(true_out,axis=1))\n",
        "    \n",
        "\n",
        "# predict the intervention using trained models\n",
        "def predict_intervention(M,N,T,intvnDataOneHot,traineeModels):\n",
        "    nll = np.zeros(M)\n",
        "    for m_index in range(M):\n",
        "        mask_cols = get_one_hot_mask(np.array([m_index]), N)\n",
        "        test_inp = intvnDataOneHot.copy()\n",
        "        true_out = (test_inp[np.ix_(range(T),mask_cols)]).copy()\n",
        "        test_inp[np.ix_(range(T2),mask_cols)] = np.zeros((T,len(mask_cols)))\n",
        "        pred = traineeModels[m_index].predict(test_inp)\n",
        "\n",
        "        nll[m_index] = np.sum((categorical_crossentropy(true_out, pred))[0])\n",
        "        \n",
        "    print(nll)\n",
        "    pred_intvn = np.argmax(nll)\n",
        "    \n",
        "    return pred_intvn\n",
        "    \n",
        "# function to generate data after applying soft intervention on intvn_var\n",
        "def apply_soft_intervention(M,N,T,C,intvnDataOneHot,intvn_var):\n",
        "\n",
        "    if (intvn_var == 0):\n",
        "        X = np.random.randint(N, size=T)\n",
        "        intvnDataOneHot[range(T),X] = 1\n",
        "        \n",
        "    for m_index in range(max(intvn_var,1),M):\n",
        "        mask_ind = np.where(C[m_index,:]==0)\n",
        "        mask_cols = get_one_hot_mask(mask_ind[0], N)\n",
        "\n",
        "        inp = intvnDataOneHot.copy()\n",
        "        inp[np.ix_(range(T),mask_cols)] = 0\n",
        "        \n",
        "        if (intvn_var == m_index):    # if intervention node\n",
        "            intvnModel = get_MLP(0,M*N,num_hidden_nodes,N)\n",
        "            pred = intvnModel.predict(inp)\n",
        "        else:\n",
        "            pred = GTmodels[m_index-1].predict(inp)\n",
        "\n",
        "        output = np.argmax(pred,axis=1)\n",
        "        intvnDataOneHot[range(T),m_index*N+output] = 1\n",
        "\n",
        "\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "    # Adjacency matrix definition: using random binary lower triangular matirx\n",
        "    C = np.random.randint(low = 0, high = 2, size = [M,M]) \n",
        "    C = np.tril(C,-1)   # sample only lower traingular portion to make it a DAG\n",
        "    C[1,0] = 1\n",
        "    T2 = int(T/2)\n",
        "    \n",
        "    GTmodels = []\n",
        "    inputDataOneHot = generate_dataset_one_hot(M,N,T,C,GTmodels)\n",
        "    \n",
        "    traineeModels = []\n",
        "    train_MLPs(M,N,int(T/2),C,traineeModels,inputDataOneHot[:T2,:])\n",
        "    \n",
        "    # derive soft intervention data using a new random MLP for the intervention node\n",
        "    intvn_var = range(M)\n",
        "    num_interventions = len(intvn_var)\n",
        "    I_N_pred = np.zeros(num_interventions)\n",
        "    \n",
        "    for intvn in range(num_interventions):\n",
        "        print('Intervention on model', intvn_var[intvn])\n",
        "    \n",
        "        intvnDataOneHot = inputDataOneHot[T2:,:].copy()\n",
        "        apply_soft_intervention(M,N,T2,C,intvnDataOneHot,intvn_var[intvn])\n",
        "    \n",
        "        I_N_pred[intvn] = predict_intervention(M,N,T2,intvnDataOneHot,traineeModels)\n",
        "    \n",
        "        print('Predicted intervention on model', I_N_pred[intvn])\n",
        "    \n",
        "    print('Actual intervention', intvn_var)\n",
        "    print('Predicted intervention', I_N_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground truth model 1\n",
            "ground truth model 2\n",
            "ground truth model 3\n",
            "ground truth model 4\n",
            "ground truth model 5\n",
            "ground truth model 6\n",
            "ground truth model 7\n",
            "ground truth model 8\n",
            "ground truth model 9\n",
            "ground truth model 10\n",
            "ground truth model 11\n",
            "ground truth model 12\n",
            "ground truth model 13\n",
            "ground truth model 14\n",
            "ground truth model 15\n",
            "ground truth model 16\n",
            "ground truth model 17\n",
            "ground truth model 18\n",
            "ground truth model 19\n",
            "[451257. 689088. 459965. 180447. 400223. 350308. 129917. 400252. 459826.\n",
            " 769368.  39908. 409947. 518672. 549696. 609420. 670336. 680015. 420057.\n",
            " 659876.  89878.]\n",
            "trainee model 0\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 2.1472 - categorical_accuracy: 0.2787 - val_loss: 0.9797 - val_categorical_accuracy: 0.3936\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.9030 - categorical_accuracy: 0.5258 - val_loss: 0.2927 - val_categorical_accuracy: 0.7953\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.6455 - categorical_accuracy: 0.6210 - val_loss: 0.2257 - val_categorical_accuracy: 0.7953\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.6188 - categorical_accuracy: 0.6252 - val_loss: 0.2224 - val_categorical_accuracy: 0.7953\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.6159 - categorical_accuracy: 0.6322 - val_loss: 0.2252 - val_categorical_accuracy: 0.7953\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.6219 - categorical_accuracy: 0.6254 - val_loss: 0.2242 - val_categorical_accuracy: 0.7953\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.6170 - categorical_accuracy: 0.6256 - val_loss: 0.2229 - val_categorical_accuracy: 0.7953\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.6245 - categorical_accuracy: 0.6248 - val_loss: 0.2254 - val_categorical_accuracy: 0.7953\n",
            "test out [7 0 7 5 1 4 7 0 8 7]\n",
            "true out [3 0 3 5 1 4 3 0 8 7]\n",
            "trainee model 1\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 1.1937 - categorical_accuracy: 0.6594 - val_loss: 1.9780e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1166 - categorical_accuracy: 0.9571 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0860 - categorical_accuracy: 0.9654 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0810 - categorical_accuracy: 0.9663 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0809 - categorical_accuracy: 0.9662 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0804 - categorical_accuracy: 0.9668 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0805 - categorical_accuracy: 0.9666 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0830 - categorical_accuracy: 0.9661 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0820 - categorical_accuracy: 0.9672 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "test out [7 7 7 0 9 7 7 7 9 7]\n",
            "true out [7 7 7 0 9 7 7 7 9 7]\n",
            "trainee model 2\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 1.2961 - categorical_accuracy: 0.6278 - val_loss: 0.1377 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1519 - categorical_accuracy: 0.9508 - val_loss: 0.0156 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0911 - categorical_accuracy: 0.9517 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0725 - categorical_accuracy: 0.9592 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0715 - categorical_accuracy: 0.9615 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0692 - categorical_accuracy: 0.9631 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0680 - categorical_accuracy: 0.9625 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0698 - categorical_accuracy: 0.9628 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0706 - categorical_accuracy: 0.9630 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0708 - categorical_accuracy: 0.9626 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "test out [5 5 5 4 5 5 5 5 5 5]\n",
            "true out [5 5 5 4 5 5 5 5 5 5]\n",
            "trainee model 3\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 1.2613 - categorical_accuracy: 0.6444 - val_loss: 9.9949e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1380 - categorical_accuracy: 0.9511 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0883 - categorical_accuracy: 0.9624 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0827 - categorical_accuracy: 0.9627 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0826 - categorical_accuracy: 0.9634 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0810 - categorical_accuracy: 0.9645 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0792 - categorical_accuracy: 0.9638 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0864 - categorical_accuracy: 0.9620 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0840 - categorical_accuracy: 0.9627 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0831 - categorical_accuracy: 0.9634 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 3129 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f280d47ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [2 2 2 5 0 2 2 2 0 2]\n",
            "true out [2 2 2 5 0 2 2 2 0 2]\n",
            "trainee model 4\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 1.2958 - categorical_accuracy: 0.6081 - val_loss: 0.2487 - val_categorical_accuracy: 0.8038\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2443 - categorical_accuracy: 0.8214 - val_loss: 1.4349e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2077 - categorical_accuracy: 0.8462 - val_loss: 4.2674e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1997 - categorical_accuracy: 0.8651 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1900 - categorical_accuracy: 0.8919 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1834 - categorical_accuracy: 0.9027 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1781 - categorical_accuracy: 0.9064 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1829 - categorical_accuracy: 0.9035 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1771 - categorical_accuracy: 0.9045 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1814 - categorical_accuracy: 0.9029 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1804 - categorical_accuracy: 0.9026 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1805 - categorical_accuracy: 0.9035 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 3130 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2810a83e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [2 2 2 4 5 5 2 2 5 2]\n",
            "true out [2 2 2 4 5 5 2 2 5 2]\n",
            "trainee model 5\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 1.3342 - categorical_accuracy: 0.6370 - val_loss: 0.2097 - val_categorical_accuracy: 0.8950\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2587 - categorical_accuracy: 0.8588 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2197 - categorical_accuracy: 0.8717 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2163 - categorical_accuracy: 0.8720 - val_loss: 0.0727 - val_categorical_accuracy: 0.8950\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2192 - categorical_accuracy: 0.8702 - val_loss: 0.0729 - val_categorical_accuracy: 0.8950\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2198 - categorical_accuracy: 0.8712 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2153 - categorical_accuracy: 0.8725 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2229 - categorical_accuracy: 0.8717 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2229 - categorical_accuracy: 0.8714 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2229 - categorical_accuracy: 0.8683 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "WARNING:tensorflow:7 out of the last 3131 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f280d1feae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [3 3 3 5 5 3 3 3 5 3]\n",
            "true out [3 3 3 5 5 3 3 3 5 3]\n",
            "trainee model 6\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.5939 - categorical_accuracy: 0.4348 - val_loss: 0.5519 - val_categorical_accuracy: 0.7051\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3568 - categorical_accuracy: 0.8229 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1962 - categorical_accuracy: 0.8926 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1910 - categorical_accuracy: 0.8946 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1945 - categorical_accuracy: 0.8861 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1908 - categorical_accuracy: 0.8938 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1864 - categorical_accuracy: 0.8967 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1912 - categorical_accuracy: 0.8907 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1941 - categorical_accuracy: 0.8901 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1977 - categorical_accuracy: 0.8773 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:8 out of the last 3132 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f281b9e36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [1 1 1 2 2 0 1 1 2 1]\n",
            "true out [1 1 1 2 2 0 1 1 2 1]\n",
            "trainee model 7\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.2272 - categorical_accuracy: 0.6701 - val_loss: 0.0714 - val_categorical_accuracy: 0.8970\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2124 - categorical_accuracy: 0.9048 - val_loss: 9.7091e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1682 - categorical_accuracy: 0.9264 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1616 - categorical_accuracy: 0.9309 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1631 - categorical_accuracy: 0.9301 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1668 - categorical_accuracy: 0.9281 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1615 - categorical_accuracy: 0.9316 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1694 - categorical_accuracy: 0.9274 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1642 - categorical_accuracy: 0.9273 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1681 - categorical_accuracy: 0.9288 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:9 out of the last 3133 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f280d0adbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [4 4 4 6 3 5 4 4 3 4]\n",
            "true out [4 4 4 6 3 5 4 4 3 4]\n",
            "trainee model 8\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.9574 - categorical_accuracy: 0.6646 - val_loss: 7.8730e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1569 - categorical_accuracy: 0.9306 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.1483 - categorical_accuracy: 0.9293 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1412 - categorical_accuracy: 0.9334 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1398 - categorical_accuracy: 0.9343 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1495 - categorical_accuracy: 0.9282 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1416 - categorical_accuracy: 0.9341 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1439 - categorical_accuracy: 0.9298 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:10 out of the last 3134 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2829fb5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [4 4 4 4 5 6 4 4 5 4]\n",
            "true out [4 4 4 4 5 6 4 4 5 4]\n",
            "trainee model 9\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.1792 - categorical_accuracy: 0.6045 - val_loss: 0.0725 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1222 - categorical_accuracy: 0.9607 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0722 - categorical_accuracy: 0.9667 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0682 - categorical_accuracy: 0.9664 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0682 - categorical_accuracy: 0.9665 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0649 - categorical_accuracy: 0.9689 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0649 - categorical_accuracy: 0.9691 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0680 - categorical_accuracy: 0.9665 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0642 - categorical_accuracy: 0.9684 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0643 - categorical_accuracy: 0.9687 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0689 - categorical_accuracy: 0.9671 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0673 - categorical_accuracy: 0.9672 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 3135 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2831018158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [9 9 9 2 6 9 9 9 6 9]\n",
            "true out [9 9 9 2 6 9 9 9 6 9]\n",
            "trainee model 10\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.9050 - categorical_accuracy: 0.8083 - val_loss: 0.1379 - val_categorical_accuracy: 0.8978\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0954 - categorical_accuracy: 0.9400 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0645 - categorical_accuracy: 0.9573 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0590 - categorical_accuracy: 0.9600 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0591 - categorical_accuracy: 0.9583 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0586 - categorical_accuracy: 0.9599 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0595 - categorical_accuracy: 0.9600 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0599 - categorical_accuracy: 0.9621 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0579 - categorical_accuracy: 0.9648 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0574 - categorical_accuracy: 0.9621 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0599 - categorical_accuracy: 0.9633 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0588 - categorical_accuracy: 0.9623 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.0613 - categorical_accuracy: 0.9582 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2821f5e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [0 0 0 0 2 0 0 0 2 0]\n",
            "true out [0 0 0 0 2 0 0 0 2 0]\n",
            "trainee model 11\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 1.4366 - categorical_accuracy: 0.5827 - val_loss: 0.2648 - val_categorical_accuracy: 0.9022\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2904 - categorical_accuracy: 0.8665 - val_loss: 0.0678 - val_categorical_accuracy: 0.9022\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2300 - categorical_accuracy: 0.8805 - val_loss: 0.0678 - val_categorical_accuracy: 0.9022\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2086 - categorical_accuracy: 0.8997 - val_loss: 0.0156 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2053 - categorical_accuracy: 0.9017 - val_loss: 0.0052 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2044 - categorical_accuracy: 0.9031 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2034 - categorical_accuracy: 0.9000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2076 - categorical_accuracy: 0.9038 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2055 - categorical_accuracy: 0.9019 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2073 - categorical_accuracy: 0.9046 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2821734598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [5 6 5 3 1 5 5 6 1 5]\n",
            "true out [5 6 5 3 1 5 5 6 1 5]\n",
            "trainee model 12\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.3449 - categorical_accuracy: 0.5798 - val_loss: 0.2052 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1653 - categorical_accuracy: 0.9230 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1044 - categorical_accuracy: 0.9398 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1005 - categorical_accuracy: 0.9393 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1023 - categorical_accuracy: 0.9433 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1003 - categorical_accuracy: 0.9394 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1013 - categorical_accuracy: 0.9408 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1019 - categorical_accuracy: 0.9389 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1014 - categorical_accuracy: 0.9426 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f281f61c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [6 6 6 1 8 6 6 6 1 6]\n",
            "true out [6 6 6 1 8 6 6 6 1 6]\n",
            "trainee model 13\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.7171 - categorical_accuracy: 0.3129 - val_loss: 0.7703 - val_categorical_accuracy: 0.6978\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.5934 - categorical_accuracy: 0.7176 - val_loss: 0.1393 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.4333 - categorical_accuracy: 0.7782 - val_loss: 0.1391 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3999 - categorical_accuracy: 0.7866 - val_loss: 0.0674 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3877 - categorical_accuracy: 0.7876 - val_loss: 0.0698 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3849 - categorical_accuracy: 0.7908 - val_loss: 1.9552e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3603 - categorical_accuracy: 0.7953 - val_loss: 4.4882e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3590 - categorical_accuracy: 0.7950 - val_loss: 1.2516e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3582 - categorical_accuracy: 0.7920 - val_loss: 3.3014e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3582 - categorical_accuracy: 0.7921 - val_loss: 6.4432e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3533 - categorical_accuracy: 0.8013 - val_loss: 1.8922e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3565 - categorical_accuracy: 0.7957 - val_loss: 1.0982e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3552 - categorical_accuracy: 0.7924 - val_loss: 7.5518e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3533 - categorical_accuracy: 0.7928 - val_loss: 6.8393e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3583 - categorical_accuracy: 0.7935 - val_loss: 8.4151e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3546 - categorical_accuracy: 0.8006 - val_loss: 4.3384e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3577 - categorical_accuracy: 0.7910 - val_loss: 4.8119e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2800b37950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [3 2 3 3 8 6 3 2 3 3]\n",
            "true out [3 2 3 3 8 6 3 2 3 3]\n",
            "trainee model 14\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.3672 - categorical_accuracy: 0.4833 - val_loss: 0.2110 - val_categorical_accuracy: 0.9013\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2921 - categorical_accuracy: 0.8546 - val_loss: 0.1421 - val_categorical_accuracy: 0.8999\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2107 - categorical_accuracy: 0.8906 - val_loss: 0.0670 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1884 - categorical_accuracy: 0.8883 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1870 - categorical_accuracy: 0.8921 - val_loss: 3.6203e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1891 - categorical_accuracy: 0.8912 - val_loss: 3.6695e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1873 - categorical_accuracy: 0.8845 - val_loss: 0.0069 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1886 - categorical_accuracy: 0.8860 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2800a7a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [7 7 7 7 7 7 7 7 7 7]\n",
            "true out [7 7 7 7 7 7 7 7 7 7]\n",
            "trainee model 15\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.1549 - categorical_accuracy: 0.6638 - val_loss: 0.2882 - val_categorical_accuracy: 0.8978\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2179 - categorical_accuracy: 0.8936 - val_loss: 7.3668e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1223 - categorical_accuracy: 0.9331 - val_loss: 4.1501e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1073 - categorical_accuracy: 0.9369 - val_loss: 2.3843e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1103 - categorical_accuracy: 0.9370 - val_loss: 4.6859e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.1081 - categorical_accuracy: 0.9361 - val_loss: 1.9337e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1086 - categorical_accuracy: 0.9374 - val_loss: 1.0483e-05 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f280d4a7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [8 8 8 1 1 8 8 8 9 8]\n",
            "true out [8 8 8 1 1 8 8 8 9 8]\n",
            "trainee model 16\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.3666 - categorical_accuracy: 0.4627 - val_loss: 0.2779 - val_categorical_accuracy: 0.9028\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3280 - categorical_accuracy: 0.8684 - val_loss: 0.1892 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2597 - categorical_accuracy: 0.8812 - val_loss: 0.0708 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2316 - categorical_accuracy: 0.8805 - val_loss: 0.0708 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2198 - categorical_accuracy: 0.8854 - val_loss: 0.0708 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2128 - categorical_accuracy: 0.8881 - val_loss: 0.0633 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2026 - categorical_accuracy: 0.8904 - val_loss: 0.0114 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2074 - categorical_accuracy: 0.8856 - val_loss: 3.9499e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2057 - categorical_accuracy: 0.8881 - val_loss: 1.0471e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2088 - categorical_accuracy: 0.8887 - val_loss: 7.2444e-05 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2829ef1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [8 8 8 8 8 2 8 8 5 8]\n",
            "true out [8 8 8 8 8 2 8 8 5 8]\n",
            "trainee model 17\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.3667 - categorical_accuracy: 0.5167 - val_loss: 0.5553 - val_categorical_accuracy: 0.7993\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.4318 - categorical_accuracy: 0.7625 - val_loss: 0.1391 - val_categorical_accuracy: 0.7993\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3197 - categorical_accuracy: 0.8362 - val_loss: 1.6039e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.2875 - categorical_accuracy: 0.8553 - val_loss: 4.0850e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2807 - categorical_accuracy: 0.8640 - val_loss: 8.9953e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2848 - categorical_accuracy: 0.8581 - val_loss: 3.9712e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2770 - categorical_accuracy: 0.8607 - val_loss: 3.4244e-05 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2854 - categorical_accuracy: 0.8603 - val_loss: 1.4298e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2896 - categorical_accuracy: 0.8609 - val_loss: 8.2309e-06 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2908 - categorical_accuracy: 0.8587 - val_loss: 9.2682e-05 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f281cb65f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [4 6 4 4 3 6 4 6 4 4]\n",
            "true out [4 6 4 4 3 6 4 6 4 4]\n",
            "trainee model 18\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.5723 - categorical_accuracy: 0.4086 - val_loss: 0.4181 - val_categorical_accuracy: 0.7978\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.4340 - categorical_accuracy: 0.8042 - val_loss: 0.1402 - val_categorical_accuracy: 0.8950\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.3093 - categorical_accuracy: 0.8559 - val_loss: 0.0882 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2711 - categorical_accuracy: 0.8671 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2629 - categorical_accuracy: 0.8705 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2604 - categorical_accuracy: 0.8733 - val_loss: 0.0728 - val_categorical_accuracy: 0.8950\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2595 - categorical_accuracy: 0.8723 - val_loss: 0.0729 - val_categorical_accuracy: 0.8950\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2639 - categorical_accuracy: 0.8728 - val_loss: 0.0734 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2508 - categorical_accuracy: 0.8720 - val_loss: 0.0735 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2400 - categorical_accuracy: 0.8718 - val_loss: 0.0224 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2372 - categorical_accuracy: 0.8742 - val_loss: 0.0104 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2368 - categorical_accuracy: 0.8743 - val_loss: 0.0011 - val_categorical_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.2393 - categorical_accuracy: 0.8727 - val_loss: 0.0010 - val_categorical_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2376 - categorical_accuracy: 0.8747 - val_loss: 1.4925e-04 - val_categorical_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2395 - categorical_accuracy: 0.8741 - val_loss: 2.5694e-04 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f28009146a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [8 8 8 9 4 8 8 8 8 8]\n",
            "true out [8 8 8 9 4 8 8 8 8 8]\n",
            "trainee model 19\n",
            "Epoch 1/100\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 1.2391 - categorical_accuracy: 0.5994 - val_loss: 0.3377 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2558 - categorical_accuracy: 0.8792 - val_loss: 1.5552e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.1777 - categorical_accuracy: 0.9052 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1783 - categorical_accuracy: 0.8950 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1790 - categorical_accuracy: 0.8987 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1764 - categorical_accuracy: 0.8992 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1690 - categorical_accuracy: 0.9018 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.1708 - categorical_accuracy: 0.9001 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1748 - categorical_accuracy: 0.8945 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.1745 - categorical_accuracy: 0.8957 - val_loss: 1.1921e-07 - val_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2800879158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "test out [1 1 1 1 1 0 1 1 1 1]\n",
            "true out [1 1 1 1 1 0 1 1 1 1]\n",
            "Intervention on model 0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f282a66f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.61180954e+01 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.61180954e+01\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 0.0\n",
            "Intervention on model 1\n",
            "[1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07\n",
            " 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07\n",
            " 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07\n",
            " 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07 1.1920929e-07]\n",
            "Predicted intervention on model 0.0\n",
            "Intervention on model 2\n",
            "[1.19209290e-07 1.19209290e-07 1.61180954e+01 1.61180954e+01\n",
            " 1.61180954e+01 1.61180954e+01 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.61180954e+01 1.61180954e+01 1.61180954e+01\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.19209290e-07 1.61180954e+01 1.19209290e-07 1.61180954e+01]\n",
            "Predicted intervention on model 2.0\n",
            "Intervention on model 3\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.61180954e+01\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 3.0\n",
            "Intervention on model 4\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.61180954e+01\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.19209290e-07 1.61180954e+01 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 4.0\n",
            "Intervention on model 5\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.61180954e+01 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 5.0\n",
            "Intervention on model 6\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01]\n",
            "Predicted intervention on model 6.0\n",
            "Intervention on model 7\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 7.0\n",
            "Intervention on model 8\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 8.0\n",
            "Intervention on model 9\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.61180954e+01 1.61180954e+01 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01]\n",
            "Predicted intervention on model 9.0\n",
            "Intervention on model 10\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 10.0\n",
            "Intervention on model 11\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 11.0\n",
            "Intervention on model 12\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 12.0\n",
            "Intervention on model 13\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.61180954e+01 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 13.0\n",
            "Intervention on model 14\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 14.0\n",
            "Intervention on model 15\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 15.0\n",
            "Intervention on model 16\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.61180954e+01 1.19209290e-07 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 16.0\n",
            "Intervention on model 17\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.61180954e+01 1.19209290e-07 1.19209290e-07]\n",
            "Predicted intervention on model 17.0\n",
            "Intervention on model 18\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.61180954e+01 1.61180954e+01]\n",
            "Predicted intervention on model 18.0\n",
            "Intervention on model 19\n",
            "[1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.19209290e-07\n",
            " 1.19209290e-07 1.19209290e-07 1.19209290e-07 1.61180954e+01]\n",
            "Predicted intervention on model 19.0\n",
            "Actual intervention range(0, 20)\n",
            "Predicted intervention [ 0.  0.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}